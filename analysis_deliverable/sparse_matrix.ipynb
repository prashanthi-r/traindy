{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfX26LhP_xC_"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import scipy\n",
        "from scipy import sparse\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsjPnsb1TT8p",
        "outputId": "67967b02-85b0-4c93-d194-882634e7e49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pickle5\n",
        "import pickle5 as pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2q9qPdakCMN",
        "outputId": "b8e641d9-d6f3-4769-a4e8-e4bd2b9322f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cust_id_file = open('drive/MyDrive/TrainDy/cust_list.npy','rb')\n",
        "cust_id_list = pickle.load(cust_id_file)\n",
        "cust_id_list.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFSOMa2CgVhL",
        "outputId": "4a429116-75f5-49f9-c317-7f239983ffe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(581186,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prod_id_file = open('drive/MyDrive/TrainDy/prod_list.npy','rb')\n",
        "prod_id_list = pickle.load(prod_id_file)\n",
        "prod_id_list.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZH1YZHtKZef",
        "outputId": "222cedf1-3eac-4323-d7f4-caac54368bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21404,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxdtWziNACOK"
      },
      "outputs": [],
      "source": [
        "cust_sparse = scipy.sparse.load_npz('drive/MyDrive/TrainDy/cust_purchase_hist_sparse_matrix.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"drive/MyDrive/TrainDy/cust_18_up.pkl\",'rb')\n",
        "cust_features = pickle.load(file)\n",
        "cust_features = cust_features.fillna(0)"
      ],
      "metadata": {
        "id": "LPQCOmiHM8uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_features.head()"
      ],
      "metadata": {
        "id": "gMcxDfhnPyzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgwKDs_qYSOh"
      },
      "outputs": [],
      "source": [
        "cust_id_to_label = cust_features.loc[:, cust_features.columns == 'customer_id']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cust_features = cust_features.loc[:, (cust_features.columns != 'customer_id') & (cust_features.columns != 'article_id') & (cust_features.columns != 'sales_channel_id')]\n",
        "cust_features = cust_features.to_numpy()\n",
        "cust_features = cust_features[:,:8]\n",
        "print(cust_features[:10])"
      ],
      "metadata": {
        "id": "gFI_8g7jNxKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "235X1A2oXmmR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d20641cb-a28b-44da-8c41-a9c15292aa38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXzddZ3v8dcne9ukTZuTlu4tSRHLIpS0lKYiiyKLI4yiwHUEHUbmXllEZ+5F53ovis6MjuMyzrihMMKoFEZ0YBwUe5VF0tKVvQgkbWm60DZJ26RL9s/94/dNewjZ2p6T38nJ+/l4nEd+5/vbPqnSd3+/7+/3/Zq7IyIikko5cRcgIiLZR+EiIiIpp3AREZGUU7iIiEjKKVxERCTlFC4iIpJyCheR42RmXzCzn4TlOWbmZpYXd129mdnjZvYXcdcho4PCRUTeJJMDUkYOhYuIiKScwkVkiMxsmpk9aGa7zWyTmd0ywOZ/bmbbzWyHmf110jEKzexbYd32sFwY1j1hZh8My9Xh6uGy8P1CM3t2kPo+ZmY1ZvYvZrbPzP5oZhf2s22OmX3ezF43s11mdq+ZTQirnww/95rZfjM7Z4h/RCKHKVxEhsDMcoD/BJ4DpgMXArea2Xv72eV8YB5wEXCbmb07tP9vYDFwBvAOYBHw+bDuCeC8sPwuYCNwbtL3J4ZQ6tlAHZAAbgd+YWaT+tjuY+FzPnAiUAz8S1jXc85Sdy9295VDOK/ImyhcRIZmIVDu7ne4e7u7bwR+CFzdz/ZfdPcD7v4C8K/ANaH9I8Ad7r7L3XcDXwQ+GtY9QRQiEP0F//dJ34caLruAb7l7h7vfD7wCXNbHdh8BvuHuG919P/A54Gr1s0iqKFxEhmY2MM3M9vZ8gL8BpvSzfX3S8uvAtLA8LXzva91K4CQzm0J0ZXMvMNPMEkRXOE8yuG3+5tFok4+frK868uj/9xE5KgoXkaGpBza5e2nSp8TdL+1n+5lJy7OA7WF5O1FQvWWdux8E1gGfAl5093ZgBfAZoM7dG4ZQ53Qzs37OnayvOjqBnYCGSpfjpnARGZrVQIuZ3WZmY8ws18xONbOF/Wz/f8xsrJmdAnwcuD+03wd83szKwxXJ/wV+krTfE8BNHLkF9niv74OZDNxiZvlm9iHg7cAjfWx3H/BpM5trZsXA3wH3u3snsBvoJuqLETkmCheRIXD3LuB9RLerNgENwI+ACf3s8gRQC/wO+Ed3/21o/zKwFngeeAFYH9qS9yvhyC2w3t8Hs4roQYIG4G+BK929sY/t7gb+LRx3E9AK3Bx+14Nh35pwC3DxEM8tcphpsjCR7GBmHwP+wt2Xxl2LiK5cREQk5RQuIiOImX0/vNjY+/P9uGsTSabbYiIiknK6chERkZTT27hBIpHwOXPmxF2GiMiIsm7dugZ3L+/dnrZwMbMiosccC8N5fu7ut5vZXGAZUEb0wthH3b09DN53L3AW0Ahc5e6bw7E+B1wPdAG3uPujof1i4J+AXOBH7v6V0N7nOQaqd86cOaxduzaFfwIiItnPzF7vqz2dt8XagAvc/R1E7wZcHJ6X/yrwTXevBPYQhQbh557Q/s2wHWY2n2j8plOAi4HvhhfYcoHvAJcA84FrwrYMcA4RERkGaQsXj+wPX/PDx4ELgJ+H9nuAK8Ly5eE7Yf2FYRiLy4Fl7t7m7puIXkxbFD61YeC9dqIrlcvDPv2dQ0REhkFaO/TDFcazRCO1LicaCnxvGGICYCvR8OWEn/UAYf0+ottah9t77dNfe9kA5+hd3w1mttbM1u7evft4flUREUmS1nBx9y53PwOYQXSlcXI6z3e03P1Od69y96ry8rf0R4mIyDEalkeR3X0v8BhwDlCaNGfEDGBbWN5GGEk2rJ9A1LF/uL3XPv21Nw5wDhERGQZpC5cw6mtpWB4DvAd4mShkrgybXQc8FJYfDt8J638f5qV4mGgSo8LwFNg8ohFq1wDzwqiuBUSd/g+Hffo7h4iIDIN0vucyFbgnPNWVAzzg7r8ysw3AMjP7MvAMcFfY/i7g38ysFmgizPDn7i+Z2QPABqL5Jm4MI9RiZjcBjxI9iny3u78UjnVbP+cQEZFhoOFfgqqqKj+W91wef2UXG3Y088nzKtNQlYhIZjOzde5e1btdw78cpxV1jXxr+Wscau+KuxQRkYyhcDlOSyrKaO/qZs3mprhLERHJGAqX47Ro7iTyc42a2qFMby4iMjooXI7T2II8zpw1kZo6hYuISA+FSwosrUzw0vZm9hwYcGxMEZFRQ+GSAtWVZbjDyo2NcZciIpIRFC4pcPqMUooL83hK/S4iIoDCJSXyc3M4e+4kVihcREQAhUvKVFcm2Nx4kPqmg3GXIiISO4VLilRXJgBYoafGREQULqly0pRiEsWF1NSqU19EROGSImZGdWUZK+oa0HhtIjLaKVxSqLoyQcP+dl7Z2RJ3KSIisVK4pFBPv8tTr6nfRURGN4VLCk0vHcPcxDhW1KnfRURGN4VLii2pKGPVxkY6urrjLkVEJDYKlxRbWpngQHsXz9XvjbsUEZHYKFxS7JyKMszQUDAiMqopXFKsdGwBp06bwAq97yIio5jCJQ2WVJaxfsseDrR1xl2KiEgsFC5psLQyQWe3s1pTH4vIKKVwSYOq2ZMoyM2hRu+7iMgopXBJgzEFuZw1eyI1et9FREYphUuaVFeW8fKOZhr2t8VdiojIsFO4pEnPUDArdfUiIqOQwiVNTps+gZLCPGr0vouIjEIKlzTJy81hcUUZNZo8TERGIYVLGi2tTFDfdIgtjZr6WERGF4VLGlVXlgHo6kVERh2FSxpVlBczZXyhxhkTkVEnbeFiZjPN7DEz22BmL5nZp0L7F8xsm5k9Gz6XJu3zOTOrNbNXzOy9Se0Xh7ZaM/tsUvtcM1sV2u83s4LQXhi+14b1c9L1ew7EzKiuSLCyrpHubk19LCKjRzqvXDqBv3L3+cBi4EYzmx/WfdPdzwifRwDCuquBU4CLge+aWa6Z5QLfAS4B5gPXJB3nq+FYlcAe4PrQfj2wJ7R/M2wXi+rKBE0H2nn5jea4ShARGXZpCxd33+Hu68NyC/AyMH2AXS4Hlrl7m7tvAmqBReFT6+4b3b0dWAZcbmYGXAD8POx/D3BF0rHuCcs/By4M2w+7nvddNEqyiIwmw9LnEm5LnQmsCk03mdnzZna3mU0MbdOB+qTdtoa2/trLgL3u3tmr/U3HCuv3he1713WDma01s7W7d+8+rt+xPydMKKKifJz6XURkVEl7uJhZMfAgcKu7NwPfAyqAM4AdwNfTXUN/3P1Od69y96ry8vK0nae6MsHqTU20d2rqYxEZHdIaLmaWTxQsP3X3XwC4+05373L3buCHRLe9ALYBM5N2nxHa+mtvBErNLK9X+5uOFdZPCNvHoroywaGOLp7ZsieuEkREhlU6nxYz4C7gZXf/RlL71KTN/hR4MSw/DFwdnvSaC8wDVgNrgHnhybACok7/h93dgceAK8P+1wEPJR3rurB8JfD7sH0sFp9YRo6hUZJFZNRI55VLNfBR4IJejx3/g5m9YGbPA+cDnwZw95eAB4ANwG+AG8MVTidwE/Ao0UMBD4RtAW4DPmNmtUR9KneF9ruAstD+GeDw48txmDAmn9NmlGqcMREZNfIG3+TYuPtTQF9PaD0ywD5/C/xtH+2P9LWfu2/kyG215PZW4ENHU2+6VVeU8YMnN9LS2kFJUX7c5YiIpJXe0B8mSysTdHU7qzdp6mMRyX4Kl2GyYPZECvNyqNH7LiIyCihchklRfi4L50xSv4uIjAoKl2G0pLKMV3a2sKulNe5SRETSSuEyjJZq6mMRGSUULsPolGkTGF+Ux1Ov6daYiGQ3hcswys0xllQkqKltIMZ3OkVE0k7hMsyqK8vYvq+VzZr6WESymMJlmPUMwa+nxkQkmylchtncxDimTihSuIhIVlO4DDMzo7oywcqNjXRp6mMRyVIKlxhUV5ax92AHG7Zr6mMRyU4KlxhUV4R+lzrdGhOR7KRwicHk8UXMm1ysfhcRyVoKl5hUVyZYs7mJ1o6uuEsREUk5hUtMqisTtHZ0s15TH4tIFlK4xOTsEyeRm2Os0BD8IpKFFC4xGV+UzztmTOAp9buISBZSuMSoujLB81v30tzaEXcpIiIppXCJUXVlgm6HpzUEv4hkGYVLjM6cVUpRfg4rFC4ikmUULjEqzMtl0dwy9buISNZRuMSsuqKM2l372dmsqY9FJHsoXGKmIfhFJBspXGI2f+p4Jo7Np0bvu4hIFlG4xCxHUx+LSBZSuGSAJZVlvNHcysaGA3GXIiKSEgqXDLBU/S4ikmUULhlg1qSxTC8do3ARkayhcMkAZsbSygQr6zT1sYhkh7SFi5nNNLPHzGyDmb1kZp8K7ZPMbLmZvRZ+TgztZmbfNrNaM3vezBYkHeu6sP1rZnZdUvtZZvZC2OfbZmYDnSOTLakso7m1kxe37Yu7FBGR45bOK5dO4K/cfT6wGLjRzOYDnwV+5+7zgN+F7wCXAPPC5wbgexAFBXA7cDawCLg9KSy+B3wiab+LQ3t/58hYS8LUx3pbX0SyQdrCxd13uPv6sNwCvAxMBy4H7gmb3QNcEZYvB+71yNNAqZlNBd4LLHf3JnffAywHLg7rxrv70x49w3tvr2P1dY6MVV5SyMknlLCiTuEiIiPfsPS5mNkc4ExgFTDF3XeEVW8AU8LydKA+abetoW2g9q19tDPAOXrXdYOZrTWztbt37z76XyzFoqmP92jqYxEZ8dIeLmZWDDwI3OruzcnrwhVHWnuwBzqHu9/p7lXuXlVeXp7OMoakurKM9s5u1r2uqY9FZGRLa7iYWT5RsPzU3X8RmneGW1qEn7tC+zZgZtLuM0LbQO0z+mgf6BwZbdHcMvJyTP0uIjLipfNpMQPuAl52928krXoY6Hni6zrgoaT2a8NTY4uBfeHW1qPARWY2MXTkXwQ8GtY1m9nicK5rex2rr3NktOLCPM6YWar3XURkxEvnlUs18FHgAjN7NnwuBb4CvMfMXgPeHb4DPAJsBGqBHwKfBHD3JuBLwJrwuSO0Ebb5UdinDvh1aO/vHBmvujLBC9v2se+gpj4WkZHLNFhipKqqyteuXRt3Gaze1MSHf7CS7//ZAi4+dWrc5YiIDMjM1rl7Ve92vaGfYc6YWcrYglwNwS8iI5rCJcMU5OWwaO4k9buIyIimcMlASysTbGw4wPa9h+IuRUTkmChcMlDPUDC6ehGRkUrhkoFOPqGEsnEFrKhTv4uIjEwKlwyUk2OcU1HGU5r6WERGKIVLhlpamWB3Sxu1u/bHXYqIyFFTuGSo6koNwS8iI1feUDc0s8uAU4CinjZ3vyMdRQnMnDSWWZPGUlPbyMer58ZdjojIURnSlYuZfR+4CrgZMOBDwOw01iVEVy+rNjbS2dUddykiIkdlqLfFlrj7tcAed/8icA5wUvrKEoiG4G9p6+R5TX0sIiPMUMOl522+g2Y2DegANPBVmh1+3+U19buIyMgy1HD5lZmVAl8D1gObgfvSVZREJo0rYP7U8dRo6mMRGWGG1KHv7l8Kiw+a2a+AInfXvZphsHRegh/XbOZQexdjCnLjLkdEZEgGvHIxswvCzw/0fIDLgAvDsqTZkooy2ru6WbO5afCNRUQyxGBXLu8Cfg/8SR/rHPhFH+2SQovmTiI/16ipbeDck8rjLkdEZEgGDBd3vz0s3uHum5LXmZlevhgGYwvyOHPWRPW7iMiIMtQO/Qf7aPt5KguR/i2tTPDS9mb2HGiPuxQRkSEZrM/lZDP7IDAhud/FzD5G0pv6kl7VlWW4w8qNGiVZREaGwfpc3ga8Dyjlzf0uLcAn0lWUvNnpM0opLszjqdoGLj1NrxeJSOYbrM/lofDo8W3u/nfDVJP0kp+bw9lzJ7FCg1iKyAgxaJ+Lu3cBVwxDLTKA6soEmxsPsnXPwbhLEREZ1FA79GvM7F/M7J1mtqDnk9bK5E16huBfUat+FxHJfEMdcv+M8DN5iH0HLkhtOdKfk6YUkygu5KnaBj68cGbc5YiIDGiow7+cn+5CZGBmRnVlGTVh6mMzi7skEZF+DXU+lylmdpeZ/Tp8n29m16e3NOmtujJBw/52XtnZEncpIiIDGmqfy4+BR4Fp4furwK3pKEj619PvUqN+FxHJcEMNl4S7PwB0A7h7J9CVtqqkT9NLxzA3MY4aPZIsIhluqOFywMzKiDrxMbPFgIbcj8GSijJWbWykQ1Mfi0gGG2q4fAZ4GKgwsxrgXuDmtFUl/VpameBAexfP1e+NuxQRkX4NKVzcfT3R8PtLgL8ETnH35wfax8zuNrNdZvZiUtsXzGybmT0bPpcmrfucmdWa2Stm9t6k9otDW62ZfTapfa6ZrQrt95tZQWgvDN9rw/o5Q/ujGBnOqSjDDJ7SrTERyWBDvXIBWAS8A1gAXGNm1w6y/Y+Bi/to/6a7nxE+j0D09BlwNXBK2Oe7ZpZrZrnAd4BLgPnhvPPDcb4ajlUJ7AF6nl67HtgT2r8ZtssapWMLOHXaBL1MKSIZbaiPIv8b8I/AUmBh+FQNtI+7PwkMdfrEy4Fl7t4W5o2pJQqzRUCtu29093ZgGXC5RS95XMCRYf/v4cgQNZeH74T1F1qWvRSypLKM9Vv2cKCtM+5SRET6NNQrlyqg2t0/6e43h88tx3jOm8zs+XDbbGJomw7UJ22zNbT1114G7A1PrSW3v+lYYf2+sP1bmNkNZrbWzNbu3r37GH+d4be0MkFnt7NaUx+LSIYaari8CJyQgvN9D6ggGk5mB/D1FBzzmLn7ne5e5e5V5eUjZwrhhXMmUZCXQ81r6ncRkcw01LHFEsAGM1sNtPU0uvv7j+Zk7r6zZ9nMfgj8KnzdBiQPmDUjtNFPeyNQamZ54eokefueY201szxgQtg+axTl53LWrInU1GXVryUiWWSo4fKFVJzMzKa6+47w9U+Jroggesz5Z2b2DaJRAOYBqwED5pnZXKLQuBr4b+7uZvYYcCVRP8x1wENJx7oOWBnW/97dPRX1Z5Kl8xJ87dFXaNjfRqK4MO5yRETeZKgDVz5xtAc2s/uA84CEmW0FbgfOM7MziF7G3Ez0WDPu/pKZPQBsADqBG8M8MpjZTURDz+QCd7v7S+EUtwHLzOzLwDPAXaH9LuDfzKyW6IGCq4+29pFgSUXUjbSyrpE/ece0QbYWERleNtA/6s2shfBWfu9VgLv7+HQVNtyqqqp87dq1cZcxZJ1d3Zz5peVcdtpUvvLB0+MuR0RGKTNb5+5veXp4sGmOS9JXkhyPvNwcFp9YRk2dOvVFJPMczUuUkmGWViaobzrElkZNfSwimUXhMoJVV0b9Lrp6EZFMo3AZwSrKi5kyvlDjjIlIxlG4jGBmRnVFgpV1jXR3Z93T1iIygilcRrjqygRNB9p5+Y3muEsRETlM4TLC9Ux9rFGSRSSTKFxGuBMmFFFRPk79LiKSURQuWaC6MsHqTU20d2rqYxHJDAqXLFBdmeBQRxfPbNkTdykiIoDCJSssPrGMHEOjJItIxlC4ZIEJY/I5bUYpNep3EZEMoXDJEtUVZTxbv5eW1o64SxERUbhki6WVCbq6ndWbNPWxiMRP4ZIlFsyeSGFeDjV630VEMoDCJUsU5eeycM4k9buISEZQuGSRJZVlvLKzhV0trXGXIiKjnMIliywNQ8Gs1CPJIhIzhUsWOWXaBMYX5enWmIjETuGSRXJzjCUVCWpqG3HXEPwiEh+FS5aprixj295DvK6pj0UkRgqXLNMzBL9GSRaROClcsszcxDimTihSv4uIxErhkmXMjOrKBCs3NtKlqY9FJCYKlyy0tDLB3oMdbNiuqY9FJB4Klyy0pKIMgJo63RoTkXgoXLLQ5PFFnDSlWP0uIhIbhUuWOv9tk/nDaw1ce/dqVm3Uey8iMrzy4i5A0uPWd5/E+DH53P3UJq6682mqZk/kxvMrOe9t5ZhZ3OWJSJYz/Ys2UlVV5WvXro27jJQ71N7FA2vr+cETdWzf18rbp47nk+dVcOlpU8nNUciIyPExs3XuXtW7PW23xczsbjPbZWYvJrVNMrPlZvZa+DkxtJuZfdvMas3seTNbkLTPdWH718zsuqT2s8zshbDPty38c7y/c4xWYwpyuW7JHB7/n+fztStPp62zi5vve4YLv/44y1Zvoa2zK+4SRSQLpbPP5cfAxb3aPgv8zt3nAb8L3wEuAeaFzw3A9yAKCuB24GxgEXB7Ulh8D/hE0n4XD3KOUa0gL4cPVc1k+affxfc+soDiojw++4sXeNc/PM5dT23iYHtn3CWKSBZJW7i4+5NA7zl3LwfuCcv3AFcktd/rkaeBUjObCrwXWO7uTe6+B1gOXBzWjXf3pz26r3dvr2P1dQ4hGtzyktOm8p83LeXeP1/E7LKxfOlXG6j+yu/59u9eY9/BjrhLFJEsMNwd+lPcfUdYfgOYEpanA/VJ220NbQO1b+2jfaBzvIWZ3UB0pcSsWbOO9ncZ0cyMc08q59yTyln3ehPffayObyx/lR88UcefnTOb65fOZXJJUdxlisgIFdujyOGKI61PEwx2Dne/092r3L2qvLw8naVktLNmT+Kujy3kkVveyQVvn8IPn9zI0q8+xuf/4wXqmzS6sogcveEOl53hlhbh567Qvg2YmbTdjNA2UPuMPtoHOocMYv608fzzNWfy+786jw8umM79a+o57x8f59P3P8urO1viLk9ERpDhDpeHgZ4nvq4DHkpqvzY8NbYY2BdubT0KXGRmE0NH/kXAo2Fds5ktDk+JXdvrWH2dQ4ZoTmIcf/+B0/nD/7qAjy+Zw29efIOLvvkkN9y7lmfr98ZdnoiMAGl7z8XM7gPOAxLATqKnvv4DeACYBbwOfNjdm0JA/AvRE18HgY+7+9pwnD8H/iYc9m/d/V9DexXRE2ljgF8DN7u7m1lZX+cYrN5sfc8lFZoOtPPjFZu5Z8Vm9h3qoLqyjBvPq+ScijK9kCkyyvX3noteogwULoPb39bJz1a9zg//sIndLW2cMbOUT55XwbvfPoUcvZApMiopXAahcBm61o4uHly/le8/UUd90yFOmlLMJ8+r5H2nTyUvV8PViYwmCpdBKFyOXmdXN796fgfffbyWV3fuZ+akMfzluRVcedYMivJz4y5PRIaBwmUQCpdj193t/O6Pu/jOY7U8W7+X8pJC/mLpXD6yeDbFhRobVSSbKVwGoXA5fu7Oyo2NfPexOp6qbWDCmHyuWzKHjy+Zw8RxBXGXJyJpoHAZhMIltZ6r38t3H6/l0Zd2MrYgl2sWzeIT7zyREyborX+RbKJwGYTCJT1e3dnC9x+v46HntpNjcOVZM7jh3ArmJsbFXZqIpIDCZRAKl/SqbzrInU9u5P619bR3drO0MsHVi2bynvlTKMxT57/ISKVwGYTCZXjsamll2ep67l9Tz7a9h5g0roAPLpjOVQtnUTm5OO7yROQoKVwGoXAZXl3dzlO1DSxbvYXlG3bS2e0snDORqxfO4tLTpjKmQFczIiOBwmUQCpf4NOxv48F1W1m2pp5NDQcoKcrjijOmc/WimZwybULc5YnIABQug1C4xM/dWbWpifvX1PNfL+ygvbOb02dM4KqFM3n/O6ZRUpQfd4ki0ovCZRAKl8yy72AHv3wmupr54xstjC3I5X2nT+XqRbM4c2apBswUyRAKl0EoXDKTu/Pc1n0sW72Fh5/bzsH2Lt42pYSrFs7kAwumUzpWL2eKxEnhMgiFS+bb39bJfz63nWWrt/Dc1n0U5OVwyakncPXCWSw+cZKuZkRioHAZhMJlZNmwvZn712zhl89so7m1kzllY7lq4SyuPGsG5SWFcZcnMmooXAahcBmZWju6eOSFHSxbU8/qTU3k5RjvfvsUrlo0k3PnlZOreWZE0krhMgiFy8hXt3s/96+p58F1W2k80M700jF8qGoGH66aybTSMXGXJ5KVFC6DULhkj/bObv7fyzu5b/UWnqptwIB3nVTOVQtnceHbJ5OvCc1EUkbhMgiFS3aqbzrIA2vreWBtPTub2ygvKeTKs2Zw9cKZzC7T4Jkix0vhMgiFS3br7OrmiVd3c9/qeh57ZRdd3c45J5Zx9aKZvPeUEzRzpsgxUrgMQuEyeuxsbuXf19Zz/9p66psOUTo2nz89czofrprJySeU6JFmkaOgcBmEwmX06e52VtQ1ct+aLfz2pTfo6HImlxSypKKMJZUJllSUMWPi2LjLFMlo/YWLJjiXUSsnx1g6L8HSeQka97exfMNOVtQ18lRtI//x7HYAZpeNjcKmIsE5FWUkivUOjchQ6Mol0JWL9HB3Xtu1n5raBmpqG1m1sZGWtk4ATj6hhCUVCaory1g0d5IG05RRT7fFBqFwkf50dnXz4vZmamobWFnXyJrNTbR1dpObY5w+YwLVFdEttAWzJ+rBABl1FC6DULjIULV2dPHMlr2sqGugpraB57buo6vbKcjLoWr2RKpDf81p0yeQp3dqJMspXAahcJFjtb+tk9WbGqmpbWRFXSMv72gGoKQwj7NPnMSSigRLKst42xQ9iSbZRx36ImlSXJjHBSdP4YKTpwDQuL+NlRujoFlR28D/e3kXAIniAhafWEZ1ZYLqigQzJ41R2EjW0pVLoCsXSZdtew+xoraBFXWN1NQ2sKulDYDppWOorozC5pwTy5g8vijmSkWOnm6LDULhIsPB3anbfYAVdQ2sqG1k5cZG9h3qAGDe5OIoaCrKWHxiGRPG6Ek0yXwZFS5mthloAbqATnevMrNJwP3AHGAz8GF332PRfYN/Ai4FDgIfc/f14TjXAZ8Ph/2yu98T2s8CfgyMAR4BPuWD/KIKF4lDV7ezYXtz9HBAXSNrNjVxqKOLHINTp09gSUWCRXMnMq10DFNKiigdm69baZJRMjFcqty9IantH4Amd/+KmX0WmOjut5nZpcDNROFyNvBP7n52CKO1QBXgwDrgrBBIq4FbgFVE4fJtd//1QDUpXCQTtHd282z93sOPPT9Tv4eOriP/jRbk5lBeUsjk8YVMLilkyvgiJpcUMrmkKLQVMWV8IRPHFpCjuWxkGIyEDv3LgfPC8j3A48BtoTAVrUUAAAxtSURBVP3ecOXxtJmVmtnUsO1yd28CMLPlwMVm9jgw3t2fDu33AlcAA4aLSCYoyMth0dxJLJo7iU+/Bw62d7JhezM7m9vY1dJ6+Oeu5jY2NRxg1aYm9h7seMtx8nIshFBRCKEjwTO5pIjyEExl4xRCkh5xhYsDvzUzB37g7ncCU9x9R1j/BjAlLE8H6pP23RraBmrf2kf7W5jZDcANALNmzTqe30ckLcYW5FE1Z9KA27R2dLG75Ujo7GppY2dz6+Gf9U0HWff6HpoOtL9l39wco7z4yJXQkTA6ckU0ZXwhZcWFmtVTjkpc4bLU3beZ2WRguZn9MXmlu3sInrQKoXYnRLfF0n0+kXQoys9l5qSxzJw08CCb7Z3d7N4fgqc5OYyiK6Jte1t5ZsteGvsIoRyDxOEQigKnvLiQ8WPyo09RPuPH5DG+KJ8J4XtxUZ4CaRSLJVzcfVv4ucvMfgksAnaa2VR33xFue+0Km28DZibtPiO0bePIbbSe9sdD+4w+thcZ1QrycpheOobpg0z53NHVTcP+tugWXHMrO1va2J10JbSzuZXnt+6j8UAbg3XZlhTmMX5MPiVFeW8Joeh7Xh9t0feSonyF0wg27OFiZuOAHHdvCcsXAXcADwPXAV8JPx8KuzwM3GRmy4g69PeFAHoU+Dszmxi2uwj4nLs3mVmzmS0m6tC/Fvjn4fr9REa6/Nwcpk4Yw9QJA4dQd7ezv72T5kMdNB/qpLm1I1puDW2tvds72L73EH98I/re0tY5aDgVF+ZFAdRfMPXZHoVZSVGeht+JURxXLlOAX4bHKfOAn7n7b8xsDfCAmV0PvA58OGz/CNGTYrVEjyJ/HCCEyJeANWG7O3o694FPcuRR5F+jznyRlMvJsegv9KJ8mDj49r0dWzi18sfWliGH07iC3LdcDfUVSiV9BFdJUT4FeQqnY6WXKAM9iiwysvQXTvsOddDS2nk4nFpaewVVa1h/qIPuQf76K8rPecuVUv8B9da20TBK9kh4FFlEZMiO98rJ3TnQ3nX4qqil9xVTuDpKbms60M7rjQcPh1jnIOlUkJdzuF+pZEw+xYW5jCvIo7gwj3HhU1yYe/j7m9vzGJe0Ln+E3eJTuIjIqGRmFIe/xKcxcP9SX9yd1o7uEEwd7Ot1a6/lLbf1OjnQ1knj/oPsb4uWD7R10d7VPaTzFeblvCWUepZL+mgvLsxjXMGRoCouOhJWY/Jz0z7Sg8JFROQYmBljCnIZU5DLlOMYdLSts4sDbV0caOs8HDr7Q/D0bjuyHK1rOtDOlqaDUVtrJwfau4Z0zhzjcPCMK8zl7/70NM4+seyYf4e+KFxERGJUmJdLYV4uk8YVHPexurudgx19B9X+to7DoZS8/kBbV1qm61a4iIhkiZycI7f6pgy+eXprifn8IiKShRQuIiKScgoXERFJOYWLiIiknMJFRERSTuEiIiIpp3AREZGUU7iIiEjKaVTkwMx2Ew31fywSQEMKy0kV1XV0VNfRUV1HJ1PrguOrbba7l/duVLikgJmt7WvI6biprqOjuo6O6jo6mVoXpKc23RYTEZGUU7iIiEjKKVxS4864C+iH6jo6quvoqK6jk6l1QRpqU5+LiIiknK5cREQk5RQuIiKScgqX42Bmd5vZLjN7Me5akpnZTDN7zMw2mNlLZvapuGsCMLMiM1ttZs+Fur4Yd03JzCzXzJ4xs1/FXUsPM9tsZi+Y2bNmtjbuenqYWamZ/dzM/mhmL5vZORlQ09vCn1PPp9nMbo27LgAz+3T4//yLZnafmR37vMgpZGafCjW9lOo/K/W5HAczOxfYD9zr7qfGXU8PM5sKTHX39WZWAqwDrnD3DTHXZcA4d99vZvnAU8Cn3P3pOOvqYWafAaqA8e7+vrjrgShcgCp3z6iX78zsHuAP7v4jMysAxrr73rjr6mFmucA24Gx3P9aXo1NVy3Si/6/Pd/dDZvYA8Ii7/zjmuk4FlgGLgHbgN8B/d/faVBxfVy7Hwd2fBJrirqM3d9/h7uvDcgvwMjA93qrAI/vD1/zwyYh/3ZjZDOAy4Edx15LpzGwCcC5wF4C7t2dSsAQXAnVxB0uSPGCMmeUBY4HtMdcD8HZglbsfdPdO4AngA6k6uMIly5nZHOBMYFW8lUTCradngV3AcnfPiLqAbwH/C+iOu5BeHPitma0zsxviLiaYC+wG/jXcRvyRmY2Lu6hergbui7sIAHffBvwjsAXYAexz99/GWxUALwLvNLMyMxsLXArMTNXBFS5ZzMyKgQeBW929Oe56ANy9y93PAGYAi8KleazM7H3ALndfF3ctfVjq7guAS4Abw63YuOUBC4DvufuZwAHgs/GWdES4Tfd+4N/jrgXAzCYClxOF8jRgnJn9WbxVgbu/DHwV+C3RLbFnga5UHV/hkqVCn8aDwE/d/Rdx19NbuI3yGHBx3LUA1cD7Q//GMuACM/tJvCVFwr96cfddwC+J7o/HbSuwNemq8+dEYZMpLgHWu/vOuAsJ3g1scvfd7t4B/AJYEnNNALj7Xe5+lrufC+wBXk3VsRUuWSh0nN8FvOzu34i7nh5mVm5mpWF5DPAe4I/xVgXu/jl3n+Huc4hup/ze3WP/l6WZjQsPZBBuO11EdCsjVu7+BlBvZm8LTRcCsT4s0ss1ZMgtsWALsNjMxob/Ni8k6geNnZlNDj9nEfW3/CxVx85L1YFGIzO7DzgPSJjZVuB2d78r3qqA6F/iHwVeCP0bAH/j7o/EWBPAVOCe8CRPDvCAu2fMY78ZaArwy+jvI/KAn7n7b+It6bCbgZ+GW1AbgY/HXA9wOITfA/xl3LX0cPdVZvZzYD3QCTxD5gwF86CZlQEdwI2pfDBDjyKLiEjK6baYiIiknMJFRERSTuEiIiIpp3AREZGUU7iIiEjKKVxkVDAzN7OvJ33/azP7QoqO/WMzuzIVxxrkPB8KIxA/1se6k8zsETN7zczWm9kDZjbFzM471lGezezWMCyIyFFTuMho0QZ8wMwScReSLAxkOFTXA59w9/N7HaMI+C+i4VjmheFivguUH2d5txINsjhk4R0mEYWLjBqdRC+ufbr3it5XHma2P/w8z8yeMLOHzGyjmX3FzD4S5qR5wcwqkg7zbjNba2avhrHKegbp/JqZrTGz583sL5OO+wcze5g+3mw3s2vC8V80s6+Gtv8LLAXuMrOv9drlvwEr3f0/exrc/XF3f9Pb/Gb2BTP766TvL5rZnDASwH9ZNM/Oi2Z2lZndQjQO1mM9V0pmdpGZrQxXRv8exq7rmXPmq2a2HviQmd1i0VxCz5vZskH+d5EspTf0ZTT5DvC8mf3DUezzDqKhyZuI3kT/kbsvsmgCtpuJ/nUPMIdo3K8Kor+QK4FriUbAXWhmhUCNmfWMhrsAONXdNyWfzMymEQ0meBbRWE+/NbMr3P0OM7sA+Gt37z1p2KlEc/Ycq4uB7e5+Wahhgrvvs2h+m/PdvSFc8X0eeLe7HzCz24DPAHeEYzSGKybMbDsw193beob7kdFHVy4yaoSRoe8FbjmK3daE+XHagDqiEWQBXiAKlB4PuHu3u79GFEInE40Fdm0YgmcVUAbMC9uv7h0swULg8TDIYSfwU6K5U9LpBeA94erjne6+r49tFgPziQLyWeA6YHbS+vuTlp8nGhrmz4iuGGUUUrjIaPMtor6L5PlHOgn/LZhZDlCQtK4tabk76Xs3b77y7z2OkgMG3OzuZ4TP3KR5PA4c12/xZi8RXekM5vDvGRQBuPurRFdSLwBfDrfgejOi+Xd6fpf57n590vrk3+cyoqvEBcCao+xXkiyhcJFRxd2bgAeIAqbHZo785fx+ohkyj9aHzCwn9MOcCLwCPAr8jzD9Qc8TXYNNqrUaeJeZJULn+DVEMwQO5GfAEjO7rKfBzM61t86Vs5kwNL6ZLSCaX6TnVtxBd/8J8DWODJ/fApSE5aeB6nC7r2fE5pN6FxLCeaa7PwbcBkwAigepX7KQ/kUho9HXgZuSvv8QeMjMniOaNOlYriq2EAXDeKJ5yFvN7EdEt87WWzS08W7gioEO4u47zOyzRHPdGPBf7v7QIPscCg8RfMvMvkU0wu3zwKeA5KfjHiS6TfcS0W26nrk7TgO+ZmbdYd//EdrvBH5jZtvd/Xwz+xhwX+g/gqgPpvf8H7nATyyaCtmAb2fgFMgyDDQqsoiIpJxui4mISMopXEREJOUULiIiknIKFxERSTmFi4iIpJzCRUREUk7hIiIiKff/AS3qKJwicHsZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def elbow_point_plot(cluster, errors):\n",
        "    \"\"\"\n",
        "    This function helps create a plot representing the tradeoff between the\n",
        "    number of clusters and the inertia values.\n",
        "\n",
        "    :param cluster: 1D np array that represents K (the number of clusters)\n",
        "    :param errors: 1D np array that represents the inertia values\n",
        "    \"\"\"\n",
        "    plt.clf()\n",
        "    plt.plot(cluster, errors)\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Inertia')\n",
        "    plt.title('elbow_plot')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def sk_learn_cluster(X, K):\n",
        "    \"\"\"\n",
        "    Performs k-means clustering using library functions (scikit-learn). You can\n",
        "    experiment with different initialization settings, but please initialize\n",
        "    without any optional arguments (other than n_clusters) before submitting.\n",
        "\n",
        "    :param X: 2D np array containing features of the songs\n",
        "    :param K: number of clusters\n",
        "    :return: a tuple of (cluster centroids, indices for each data point)\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    km = KMeans(n_clusters=K)\n",
        "    res = km.fit(X)\n",
        "\n",
        "    return (res.cluster_centers_, res.labels_, res.inertia_)\n",
        "\n",
        "\n",
        "def min_max_scale(data):\n",
        "    \"\"\"\n",
        "    Pre-processes the data by performing MinMax scaling.\n",
        "\n",
        "    MinMax scaling prevents different scales of the data features from\n",
        "    influencing distance calculations.\n",
        "\n",
        "    MinMax scaling is performed by\n",
        "        X_new = (X - X_min) / (X_max - X_min),\n",
        "\n",
        "    where X_new is the newly scaled value, X_min is the minimum and X_max is the\n",
        "    maximum along a single feature column.\n",
        "\n",
        "    :param data: 2D numpy array of raw data\n",
        "    :return: preprocessed data\n",
        "    \"\"\"\n",
        "    # TODO: Standardize each column's features by subtracting the columns min and\n",
        "    # dividing by the column's max - the column's min\n",
        "    data = (data - np.amin(data,axis=0))/(data.ptp(axis=0) + 1e-5)\n",
        "    return data\n",
        "\n",
        "\n",
        "def one_hot(labels, class_size):\n",
        "    \"\"\"\n",
        "    Create one hot label matrix of size (N, C)\n",
        "\n",
        "    Inputs:\n",
        "    - labels: Labels Tensor of shape (N,) representing a ground-truth label\n",
        "    for each MNIST image\n",
        "    - class_size: Scalar representing of target classes our dataset \n",
        "    Returns:\n",
        "    - targets: One-hot label matrix of (N, C), where targets[i, j] = 1 when \n",
        "    the ground truth label for image i is j, and targets[i, :j] & \n",
        "    targets[i, j + 1:] are equal to 0\n",
        "    \"\"\"\n",
        "    targets = np.zeros((labels.shape[0], class_size))\n",
        "    for i, label in enumerate(labels):\n",
        "        targets[i, label] = 1\n",
        "    targets = tf.convert_to_tensor(targets)\n",
        "    targets = tf.cast(targets, tf.float32)\n",
        "    return targets\n",
        "\n",
        "scaled_data = min_max_scale(cust_features)\n",
        "errors = []\n",
        "k_val = []\n",
        "for i in range(1,10):\n",
        "    cent,ids,inert = sk_learn_cluster(scaled_data,i)\n",
        "    errors.append(inert)\n",
        "    k_val.append(i)\n",
        "\n",
        "elbow_point_plot(k_val,errors)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_data = min_max_scale(cust_features)\n",
        "cent, ids, inert = sk_learn_cluster(scaled_data, 5)"
      ],
      "metadata": {
        "id": "5308XonXapTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_id_to_label['labels'] = ids"
      ],
      "metadata": {
        "id": "Do15zp1Xa9Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlWOPPMGDOr-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Activation, Input\n",
        "from tensorflow.math import exp, sqrt, square\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "class CVAE(tf.keras.Model):\n",
        "    def __init__(self, input_size, latent_size=15):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.input_size = input_size# H*W\n",
        "        self.latent_size =  latent_size# Z\n",
        "        self.hidden_dim = 1024  # H_d\n",
        "        self.encoder = Sequential(\n",
        "                [\n",
        "        Dense(self.hidden_dim, activation=\"relu\", name=\"layer1\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.L2(1e-4),),\n",
        "        Dense(self.hidden_dim, activation=\"relu\", name=\"layer2\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.L2(1e-4),),\n",
        "        Dense(self.hidden_dim, activation=\"relu\", name=\"layer3\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.L2(1e-4),),\n",
        "    ]\n",
        "        )\n",
        "        self.mu_layer = Dense(self.latent_size, name=\"mu_layer\")\n",
        "        self.logvar_layer = Dense(self.latent_size, name=\"logvar_layer\")\n",
        "        self.decoder = Sequential(\n",
        "                [\n",
        "        Dense(self.hidden_dim, activation=\"relu\", name=\"dec_layer1\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.L2(1e-4)),\n",
        "        Dense(self.hidden_dim, activation=\"relu\", name=\"dec_layer2\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.L2(1e-4)),\n",
        "        Dense(self.hidden_dim, activation=\"relu\", name=\"dec_layer3\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.L2(1e-4)),\n",
        "        Dense(self.input_size, name=\"dec_layer4\", activation='sigmoid'),\n",
        "    ]\n",
        "        )\n",
        "\n",
        "        ############################################################################################\n",
        "        # TODO: Implement the fully-connected encoder architecture described in the notebook.      #\n",
        "        # Specifically, self.encoder should be a network that inputs a batch of input images of    #\n",
        "        # shape (N, 1, H, W) into a batch of hidden features of shape (N, H_d). Set up             #\n",
        "        # self.mu_layer and self.logvar_layer to be a pair of linear layers that map the hidden    #\n",
        "        # features into estimates of the mean and log-variance of the posterior over the latent    #\n",
        "        # vectors; the mean and log-variance estimates will both be tensors of shape (N, Z).       #\n",
        "        ############################################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "\n",
        "        ############################################################################################\n",
        "        # TODO: Implement the fully-connected decoder architecture described in the notebook.      #\n",
        "        # Specifically, self.decoder should be a network that inputs a batch of latent vectors of  #\n",
        "        # shape (N, Z) and outputs a tensor of estimated images of shape (N, 1, H, W).             #\n",
        "        ############################################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "\n",
        "        ############################################################################################\n",
        "        #                                      END OF YOUR CODE                                    #\n",
        "        ############################################################################################\n",
        "\n",
        "    def call(self, x,c):\n",
        "        \"\"\"\n",
        "        Performs forward pass through FC-VAE model by passing image through \n",
        "        encoder, reparametrize trick, and decoder models\n",
        "    \n",
        "        Inputs:\n",
        "        - x: Batch of input images of shape (N, 1, H, W)\n",
        "        \n",
        "        Returns:\n",
        "        - x_hat: Reconstruced input data of shape (N,1,H,W)\n",
        "        - mu: Matrix representing estimated posterior mu (N, Z), with Z latent space dimension\n",
        "        - logvar: Matrix representing estimataed variance in log-space (N, Z), with Z latent space dimension\n",
        "        \"\"\"\n",
        "        x_hat = None\n",
        "        mu = None\n",
        "        logvar = None\n",
        "        ############################################################################################\n",
        "        # TODO: Implement the forward pass by following these steps                                #\n",
        "        # (1) Pass the input batch through the encoder model to get posterior mu and logvariance   #\n",
        "        # (2) Reparametrize to compute  the latent vector z                                        #\n",
        "        # (3) Pass z through the decoder to resconstruct x                                         #\n",
        "        ############################################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "        \n",
        "        x_hat = None\n",
        "        mu = None\n",
        "        logvar = None\n",
        "        \n",
        "        x = tf.cast(x, tf.float32)\n",
        "        conditioned_x = tf.concat([x,c],axis = 1)\n",
        "        encoded_input = self.encoder(conditioned_x)\n",
        "        mu = self.mu_layer(encoded_input)\n",
        "        logvar = self.logvar_layer(encoded_input)\n",
        "        z = reparametrize(mu, logvar)\n",
        "        conditioned_z = tf.concat([z,c],axis = 1)\n",
        "        x_hat = self.decoder(conditioned_z)\n",
        "\n",
        "        ############################################################################################\n",
        "        #                                      END OF YOUR CODE                                    #\n",
        "        ############################################################################################\n",
        "        return x_hat, mu, logvar\n",
        "\n",
        "\n",
        "\n",
        "def reparametrize(mu, logvar):\n",
        "    \"\"\"\n",
        "    Differentiably sample random Gaussian data with specified mean and variance using the\n",
        "    reparameterization trick.\n",
        "\n",
        "    Suppose we want to sample a random number z from a Gaussian distribution with mean mu and\n",
        "    standard deviation sigma, such that we can backpropagate from the z back to mu and sigma.\n",
        "    We can achieve this by first sampling a random value epsilon from a standard Gaussian\n",
        "    distribution with zero mean and unit variance, then setting z = sigma * epsilon + mu.\n",
        "\n",
        "    For more stable training when integrating this function into a neural network, it helps to\n",
        "    pass this function the log of the variance of the distribution from which to sample, rather\n",
        "    than specifying the standard deviation directly.\n",
        "\n",
        "    Inputs:\n",
        "    - mu: Tensor of shape (N, Z) giving means\n",
        "    - logvar: Tensor of shape (N, Z) giving log-variances\n",
        "\n",
        "    Returns: \n",
        "    - z: Estimated latent vectors, where z[i, j] is a random value sampled from a Gaussian with\n",
        "         mean mu[i, j] and log-variance logvar[i, j].\n",
        "    \"\"\"\n",
        "    epsilon = tf.random.normal([mu.shape[0],mu.shape[1]])\n",
        "    sigma = tf.math.sqrt(tf.math.exp(logvar))\n",
        "    z = sigma * epsilon + mu\n",
        "    return z\n",
        "\n",
        "\n",
        "\n",
        "def bce_function(x_hat, x):\n",
        "    \"\"\"\n",
        "    Computes the reconstruction loss of the VAE.\n",
        "    \n",
        "    Inputs:\n",
        "    - x_hat: Reconstructed input data of shape (N, 1, H, W)\n",
        "    - x: Input data for this timestep of shape (N, 1, H, W)\n",
        "    \n",
        "    Returns:\n",
        "    - reconstruction_loss: Tensor containing the scalar loss for the reconstruction loss term.\n",
        "    \"\"\"\n",
        "    bce_fn = tf.keras.losses.BinaryCrossentropy(\n",
        "        from_logits=False, \n",
        "        reduction=tf.keras.losses.Reduction.SUM,\n",
        "    )\n",
        "    reconstruction_loss = bce_fn(x, x_hat) * x.shape[-1]  # Sum over all loss terms for each data point. This looks weird, but we need this to work...\n",
        "    return reconstruction_loss\n",
        "\n",
        "def loss_function(x_hat, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    Computes the negative variational lower bound loss term of the VAE (refer to formulation in notebook).\n",
        "    Returned loss is the average loss per sample in the current batch.\n",
        "\n",
        "    Inputs:\n",
        "    - x_hat: Reconstructed input data of shape (N, 1, H, W)\n",
        "    - x: Input data for this timestep of shape (N, 1, H, W)\n",
        "    - mu: Matrix representing estimated posterior mu (N, Z), with Z latent space dimension\n",
        "    - logvar: Matrix representing estimated variance in log-space (N, Z), with Z latent space dimension\n",
        "    \n",
        "    Returns:\n",
        "    - loss: Tensor containing the scalar loss for the negative variational lowerbound\n",
        "    \"\"\"\n",
        "    #reconstruction_loss = bce_function(x_hat, x)\n",
        "    kl_divergence = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar))\n",
        "    csim = tf.keras.losses.CosineSimilarity()\n",
        "    loss = 30*csim(x,x_hat)+kl_divergence\n",
        "    \n",
        "    ################################################################################################\n",
        "    # TODO: Compute negative variational lowerbound loss as described in the notebook              #\n",
        "    ################################################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    \n",
        "    ################################################################################################\n",
        "    #                            END OF YOUR CODE                                                  #\n",
        "    ################################################################################################\n",
        "    return loss/x.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHh-i9ESE4fL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9349a7-f272-42b5-a02d-406b91d5e5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.99993825 0.9529606  0.9731382  ... 0.5092013  0.24263722 0.79343534], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 0    Loss: tf.Tensor(0.0007572991, shape=(), dtype=float32)\n",
            "tf.Tensor([0.99999976 0.20748478 0.98411477 ... 0.07657436 0.04560762 0.26737702], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 1    Loss: tf.Tensor(-0.0011165268, shape=(), dtype=float32)\n",
            "tf.Tensor([0.9999994  0.28702718 0.5979698  ... 0.07381888 0.03005882 0.25583845], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 2    Loss: tf.Tensor(-0.0012417742, shape=(), dtype=float32)\n",
            "tf.Tensor([0.99999094 0.18002075 0.21014291 ... 0.06587173 0.0335303  0.24045797], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 3    Loss: tf.Tensor(-0.0012997994, shape=(), dtype=float32)\n",
            "tf.Tensor([0.9999465  0.20805258 0.31651577 ... 0.05931315 0.03921026 0.22707179], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 4    Loss: tf.Tensor(-0.001343618, shape=(), dtype=float32)\n",
            "tf.Tensor([0.99995935 0.16916797 0.20830067 ... 0.03794413 0.02557126 0.17815848], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 5    Loss: tf.Tensor(-0.0013814719, shape=(), dtype=float32)\n",
            "tf.Tensor([0.9998895  0.15207875 0.2537086  ... 0.05069198 0.0265574  0.15752941], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 6    Loss: tf.Tensor(-0.0014141101, shape=(), dtype=float32)\n",
            "tf.Tensor([0.9998932  0.10996412 0.22050537 ... 0.04041324 0.02010559 0.11594258], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 7    Loss: tf.Tensor(-0.0014404703, shape=(), dtype=float32)\n",
            "tf.Tensor([0.9997204  0.13921733 0.20727204 ... 0.0374652  0.02346941 0.13034171], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 8    Loss: tf.Tensor(-0.0014667244, shape=(), dtype=float32)\n",
            "tf.Tensor([0.9989655  0.14795393 0.20188381 ... 0.04669356 0.02938864 0.13084707], shape=(21404,), dtype=float32)\n",
            "Train Epoch: 9    Loss: tf.Tensor(-0.0014880383, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "    X = sparse.csr_matrix(X)  \n",
        "    coo = X.tocoo()\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\n",
        "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "\n",
        "def train_vae(model, X, is_cvae=False):\n",
        "    \"\"\"\n",
        "    Train your VAE with one epoch.\n",
        "\n",
        "    Inputs:\n",
        "    - model: Your VAE instance.\n",
        "    - train_loader: A tf.data.Dataset of MNIST dataset.\n",
        "    - args: All arguments.\n",
        "    - is_cvae: A boolean flag for Conditional-VAE. If your model is a Conditional-VAE,\n",
        "    set is_cvae=True. If it's a Vanilla-VAE, set is_cvae=False.\n",
        "\n",
        "    Returns:\n",
        "    - total_loss: Sum of loss values of all batches.\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    for batch in range(50):\n",
        "        batch_inputs = cust_sparse[batch*1000:1000*batch +1000,:].toarray()\n",
        "        batch_labels_id = cust_id_list[batch*1000:1000*batch +1000]\n",
        "        batch_labels = one_hot(cust_id_to_label[cust_id_to_label['customer_id'].isin(batch_labels_id)]['labels'].to_numpy(),5)\n",
        "        with tf.GradientTape() as tape:\n",
        "            if not is_cvae:\n",
        "                x_hat, mu, logvar = model.call(batch_inputs, batch_labels)\n",
        "                batch_inputs = tf.cast(batch_inputs, tf.float32)\n",
        "            loss = loss_function(x_hat, batch_inputs, mu, logvar)\n",
        "            total_loss += loss\n",
        "        \n",
        "        gradients = tape.gradient(loss,model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "    print(x_hat[0])\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "\n",
        "model = CVAE(21404, latent_size=512)\n",
        "\n",
        "for epoch_id in range(10):\n",
        "    total_loss = train_vae(model, cust_sparse, is_cvae=False)\n",
        "    #print(f\"Train Epoch: {epoch_id} \\tLoss: {total_loss/len(train_dataset):.6f}\")\n",
        "    print(\"Train Epoch: \" + str(epoch_id) + '    Loss: ' + str(total_loss/50))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"my_model_3.h5\")"
      ],
      "metadata": {
        "id": "k4KLWPhn3wuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W8pVluYHTEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d74dd4-6bfc-45ee-c118-f44ae2fb3dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9996847  0.10322639 0.18288785 ... 0.02937494 0.01800176 0.09993609]\n",
            "166\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def predict(cust_id, model, latent_size):\n",
        "    \"\"\"\n",
        "    Call this only if the model is VAE!\n",
        "    Generate 10 images from random vectors.\n",
        "    Show the generated images from your trained VAE.\n",
        "    Image will be saved to outputs/show_vae_images.pdf\n",
        "\n",
        "    Inputs:\n",
        "    - model: Your trained model.\n",
        "    - latent_size: Latent size of your model.\n",
        "    \"\"\"\n",
        "    # Generated images from vectors of random values.\n",
        "\n",
        "    num_generation = 5\n",
        "    num_classes = 5\n",
        "    num_per_class = num_generation // num_classes\n",
        "    c = tf.eye(num_classes) # [one hot labels for 0-9]\n",
        "    z = []\n",
        "    label = cust_id_to_label[cust_id_to_label['customer_id']==cust_id]['labels'].to_numpy()[0]\n",
        "    curr_c = c[label]\n",
        "    curr_c = tf.broadcast_to(curr_c, [num_per_class, len(curr_c)])\n",
        "    curr_z = tf.random.normal(shape=[num_per_class,latent_size])\n",
        "    curr_z = tf.concat([curr_z,curr_c], axis=-1)\n",
        "    z.append(curr_z)\n",
        "    z = np.concatenate(z)\n",
        "    samples = model.decoder(z).numpy()\n",
        "    return np.array(samples[0])\n",
        "\n",
        "\n",
        "def get_top_n_products(n, pred):\n",
        "    pred[pred>0.5] = 1\n",
        "    pred[pred<=0.5] = 0\n",
        "    indices = np.where(pred==1)\n",
        "    recommended_prod_ids = prod_id_list[indices]\n",
        "    return recommended_prod_ids\n",
        "      \n",
        "\n",
        "pred = predict('00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657', model, 512)\n",
        "print(pred)\n",
        "top_rec = get_top_n_products(20,pred)\n",
        "print(len(top_rec))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transact_2019 = open('/content/drive/MyDrive/TrainDy/TAC_19.pkl', 'rb')\n",
        "transactions_data = pickle.load(transact_2019)"
      ],
      "metadata": {
        "id": "tone53L6imNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_data.head()"
      ],
      "metadata": {
        "id": "dR-VUQHTlPrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_data = transactions_data[transactions_data['customer_id'].isin(cust_id_list)]\n",
        "transactions_data.head()"
      ],
      "metadata": {
        "id": "NnamKbK0lg_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "790796a1-8d40-4064-dde9-a919cff615dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               customer_id  product_code\n",
              "4411262  0005f3aab821000881d74b72fde2d9b3e4742cf8613668...        304766\n",
              "4411265  000ca60ca6d8de6d3b4689e2da829d69db5947bd89084c...        662916\n",
              "4411266  000ca60ca6d8de6d3b4689e2da829d69db5947bd89084c...        740909\n",
              "4411267  001ea5b25c75e6490705b22abb670e08007967c631a4c5...        666382\n",
              "4411270  00497856651e5483f26917703886e95c6e299a74928740...        665532"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7617291c-ad00-4367-a45f-67cef00a06d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4411262</th>\n",
              "      <td>0005f3aab821000881d74b72fde2d9b3e4742cf8613668...</td>\n",
              "      <td>304766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411265</th>\n",
              "      <td>000ca60ca6d8de6d3b4689e2da829d69db5947bd89084c...</td>\n",
              "      <td>662916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411266</th>\n",
              "      <td>000ca60ca6d8de6d3b4689e2da829d69db5947bd89084c...</td>\n",
              "      <td>740909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411267</th>\n",
              "      <td>001ea5b25c75e6490705b22abb670e08007967c631a4c5...</td>\n",
              "      <td>666382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411270</th>\n",
              "      <td>00497856651e5483f26917703886e95c6e299a74928740...</td>\n",
              "      <td>665532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7617291c-ad00-4367-a45f-67cef00a06d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7617291c-ad00-4367-a45f-67cef00a06d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7617291c-ad00-4367-a45f-67cef00a06d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ret_cust = transactions_data['customer_id'].unique()"
      ],
      "metadata": {
        "id": "w3qCixnVAbt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall = 0\n",
        "count = 0\n",
        "for c in unique_ret_cust[:100]:\n",
        "  print(count)\n",
        "  count+=1\n",
        "  pred = predict(c, model, 512)\n",
        "  top_rec = get_top_n_products(20,pred)\n",
        "  # print(\"Number of products she purchased: \",transactions_data[(transactions_data['customer_id']==c)].shape[0])\n",
        "  a = transactions_data[(transactions_data['customer_id']==c)].shape[0]\n",
        "  # print(\"Number of products matched: \",transactions_data[(transactions_data['customer_id']==c)& (transactions_data['product_code'].isin(top_rec))].shape[0])\n",
        "  b = transactions_data[(transactions_data['customer_id']==c)&(transactions_data['product_code'].isin(top_rec))].shape[0]\n",
        "  print(b,len(top_rec))\n",
        "  if b>0:\n",
        "    recall += 1\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "6k8emhyAm9cW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed0acdc-f3fd-41c8-b111-84b52907efa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0 163\n",
            "1\n",
            "0 164\n",
            "2\n",
            "1 166\n",
            "3\n",
            "3 164\n",
            "4\n",
            "0 164\n",
            "5\n",
            "0 163\n",
            "6\n",
            "6 168\n",
            "7\n",
            "0 167\n",
            "8\n",
            "11 167\n",
            "9\n",
            "3 166\n",
            "10\n",
            "2 167\n",
            "11\n",
            "2 165\n",
            "12\n",
            "0 165\n",
            "13\n",
            "0 168\n",
            "14\n",
            "1 164\n",
            "15\n",
            "3 164\n",
            "16\n",
            "12 163\n",
            "17\n",
            "3 165\n",
            "18\n",
            "6 169\n",
            "19\n",
            "0 166\n",
            "20\n",
            "0 164\n",
            "21\n",
            "6 167\n",
            "22\n",
            "0 165\n",
            "23\n",
            "1 162\n",
            "24\n",
            "4 165\n",
            "25\n",
            "4 165\n",
            "26\n",
            "2 163\n",
            "27\n",
            "12 167\n",
            "28\n",
            "4 164\n",
            "29\n",
            "2 167\n",
            "30\n",
            "0 166\n",
            "31\n",
            "0 169\n",
            "32\n",
            "4 166\n",
            "33\n",
            "4 168\n",
            "34\n",
            "2 167\n",
            "35\n",
            "2 164\n",
            "36\n",
            "1 166\n",
            "37\n",
            "1 166\n",
            "38\n",
            "4 168\n",
            "39\n",
            "9 165\n",
            "40\n",
            "1 165\n",
            "41\n",
            "0 165\n",
            "42\n",
            "1 165\n",
            "43\n",
            "8 166\n",
            "44\n",
            "0 166\n",
            "45\n",
            "3 168\n",
            "46\n",
            "0 166\n",
            "47\n",
            "9 165\n",
            "48\n",
            "1 167\n",
            "49\n",
            "4 167\n",
            "50\n",
            "1 165\n",
            "51\n",
            "3 166\n",
            "52\n",
            "1 165\n",
            "53\n",
            "1 165\n",
            "54\n",
            "6 167\n",
            "55\n",
            "1 164\n",
            "56\n",
            "0 163\n",
            "57\n",
            "2 166\n",
            "58\n",
            "8 163\n",
            "59\n",
            "0 165\n",
            "60\n",
            "14 164\n",
            "61\n",
            "1 162\n",
            "62\n",
            "0 164\n",
            "63\n",
            "1 166\n",
            "64\n",
            "9 164\n",
            "65\n",
            "0 165\n",
            "66\n",
            "16 163\n",
            "67\n",
            "8 168\n",
            "68\n",
            "2 166\n",
            "69\n",
            "2 169\n",
            "70\n",
            "0 163\n",
            "71\n",
            "7 164\n",
            "72\n",
            "0 164\n",
            "73\n",
            "0 166\n",
            "74\n",
            "5 167\n",
            "75\n",
            "2 167\n",
            "76\n",
            "0 165\n",
            "77\n",
            "2 167\n",
            "78\n",
            "3 165\n",
            "79\n",
            "0 162\n",
            "80\n",
            "2 167\n",
            "81\n",
            "0 165\n",
            "82\n",
            "5 166\n",
            "83\n",
            "1 168\n",
            "84\n",
            "4 166\n",
            "85\n",
            "4 165\n",
            "86\n",
            "6 166\n",
            "87\n",
            "9 163\n",
            "88\n",
            "3 163\n",
            "89\n",
            "1 165\n",
            "90\n",
            "13 165\n",
            "91\n",
            "0 165\n",
            "92\n",
            "2 166\n",
            "93\n",
            "11 167\n",
            "94\n",
            "0 164\n",
            "95\n",
            "3 165\n",
            "96\n",
            "3 165\n",
            "97\n",
            "5 165\n",
            "98\n",
            "2 166\n",
            "99\n",
            "2 163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(recall)\n",
        "success_score = recall/100\n",
        "print(success_score)"
      ],
      "metadata": {
        "id": "zomo_2vi9FPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b2a6a5-03e8-4af4-cba6-6335e4431df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n",
            "0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CROSS VALIDATION"
      ],
      "metadata": {
        "id": "aQk7R9vZ-Xfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "1EXEHraP-Dal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(10, True, 1)\n",
        "for _ in cust_id_list.shape[0]/10:\n",
        "  for train_ind, test_ind in kfold.split(len(cust_sparse)):\n",
        "    train = cust_sparse[train_ind].toarray()\n",
        "    test = unique_ret_cust[test_ind]\n",
        "    for epoch_id in range(10):\n",
        "      total_loss = train_vae(model, train, is_cvae=False)\n",
        "      #print(f\"Train Epoch: {epoch_id} \\tLoss: {total_loss/len(train_dataset):.6f}\")\n",
        "      print(\"Train Epoch: \" + str(epoch_id) + '    Loss: ' + str(total_loss/50))\n",
        "    for c in test:\n",
        "      pred = predict(c, model, 512)\n",
        "      top_rec = get_top_n_products(20,pred)\n",
        "      a = transactions_data[(transactions_data['customer_id']==c)].shape[0]\n",
        "      b = transactions_data[(transactions_data['customer_id']==c)&(transactions_data['product_code'].isin(top_rec))].shape[0]\n",
        "      print(b,len(top_rec))\n",
        "      if b>0:\n",
        "        recall += 1\n",
        "    success_score = recall/len(test)\n"
      ],
      "metadata": {
        "id": "Yr7QyTQqiWZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sparse_matrix.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}